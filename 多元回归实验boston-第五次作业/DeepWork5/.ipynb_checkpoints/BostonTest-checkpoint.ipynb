{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 波士顿房价实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "# 在Jupyter中显示图像\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载波士顿房价数据\n",
    "boston_housing = tf.keras.datasets.boston_housing\n",
    "(x_data, y_data), (_, _) = boston_housing.load_data(test_split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载波士顿房价数据\n",
    "df = pd.read_csv(\"data/boston.csv\", header=0)\n",
    "\n",
    "# print(df.describe())\n",
    "\n",
    "ds = df.values\n",
    "\n",
    "# print(ds.shape)\n",
    "\n",
    "x_data = ds[:, :12]\n",
    "y_data = ds[:, 12]\n",
    "\n",
    "# for i in range(12):\n",
    "#     x_data[:, i] = (x_data[:,i] - x_data[:,i].min()) / (x_data[:,i].max()-x_data[:,i].min())\n",
    "\n",
    "\n",
    "# print(x_data.shape)\n",
    "# print(y_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分数据\n",
    "train_num = 300\n",
    "valid_num = 100\n",
    "test_num = len(x_data) - train_num - valid_num\n",
    "\n",
    "# 训练数据集\n",
    "x_train = x_data[:train_num]\n",
    "y_train = y_data[:train_num]\n",
    "\n",
    "# 验证数据集\n",
    "x_valid = x_data[train_num:train_num+valid_num]\n",
    "y_valid = y_data[train_num:train_num+valid_num]\n",
    "\n",
    "# 测试数据集\n",
    "x_test = x_data[train_num+valid_num:train_num+valid_num+test_num]\n",
    "y_test = y_data[train_num+valid_num:train_num+valid_num+test_num]\n",
    "\n",
    "# print(x_test.shape)\n",
    "# print(y_test.shape)\n",
    "# x_test\n",
    "# y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换类型并进行数据处理（归一化）\n",
    "x_train = tf.cast(scale(x_train), dtype=tf.float32)\n",
    "x_valid = tf.cast(scale(x_valid), dtype=tf.float32)\n",
    "x_test = tf.cast(scale(x_test), dtype=tf.float32)\n",
    "# x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造模型\n",
    "def model(x, w, b):\n",
    "    return tf.matmul(x, w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 优化变量\n",
    "W = tf.Variable(tf.random.normal([13, 1], mean=0.0, stddev=1.0, dtype=tf.float32))\n",
    "B = tf.Variable(tf.zeros(1), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数\n",
    "training_epochs = 100    # 迭代次数\n",
    "learning_rate = 0.01    # 学习率\n",
    "batch_size = 30    # 每批次样本数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "def loss(x, y, w, b):\n",
    "    err = model(x, w, b) - y\n",
    "    squared_err = tf.square(err)\n",
    "    return tf.reduce_mean(squared_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 梯度\n",
    "def grad(x, y, w, b):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_ = loss(x, y, w, b)\n",
    "    return tape.gradient(loss_, [w, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 优化器\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=  1, train_loss=396.5642, valid_loss=511.3394\n",
      "epoch=  2, train_loss=290.2681, valid_loss=389.2284\n",
      "epoch=  3, train_loss=219.7119, valid_loss=305.8733\n",
      "epoch=  4, train_loss=172.6949, valid_loss=248.4342\n",
      "epoch=  5, train_loss=141.3487, valid_loss=208.5883\n",
      "epoch=  6, train_loss=120.4469, valid_loss=180.7518\n",
      "epoch=  7, train_loss=106.5071, valid_loss=161.1533\n",
      "epoch=  8, train_loss=97.2081, valid_loss=147.2367\n",
      "epoch=  9, train_loss=91.0029, valid_loss=137.2633\n",
      "epoch= 10, train_loss=86.8603, valid_loss=130.0459\n",
      "epoch= 11, train_loss=84.0933, valid_loss=124.7694\n",
      "epoch= 12, train_loss=82.2436, valid_loss=120.8720\n",
      "epoch= 13, train_loss=81.0059, valid_loss=117.9632\n",
      "epoch= 14, train_loss=80.1766, valid_loss=115.7703\n",
      "epoch= 15, train_loss=79.6201, valid_loss=114.1009\n",
      "epoch= 16, train_loss=79.2457, valid_loss=112.8185\n",
      "epoch= 17, train_loss=78.9932, valid_loss=111.8250\n",
      "epoch= 18, train_loss=78.8223, valid_loss=111.0494\n",
      "epoch= 19, train_loss=78.7059, valid_loss=110.4398\n",
      "epoch= 20, train_loss=78.6264, valid_loss=109.9577\n",
      "epoch= 21, train_loss=78.5715, valid_loss=109.5745\n",
      "epoch= 22, train_loss=78.5333, valid_loss=109.2684\n",
      "epoch= 23, train_loss=78.5065, valid_loss=109.0231\n",
      "epoch= 24, train_loss=78.4874, valid_loss=108.8259\n",
      "epoch= 25, train_loss=78.4736, valid_loss=108.6669\n",
      "epoch= 26, train_loss=78.4635, valid_loss=108.5384\n",
      "epoch= 27, train_loss=78.4560, valid_loss=108.4343\n",
      "epoch= 28, train_loss=78.4504, valid_loss=108.3501\n",
      "epoch= 29, train_loss=78.4460, valid_loss=108.2817\n",
      "epoch= 30, train_loss=78.4427, valid_loss=108.2261\n",
      "epoch= 31, train_loss=78.4400, valid_loss=108.1811\n",
      "epoch= 32, train_loss=78.4380, valid_loss=108.1445\n",
      "epoch= 33, train_loss=78.4363, valid_loss=108.1148\n",
      "epoch= 34, train_loss=78.4350, valid_loss=108.0908\n",
      "epoch= 35, train_loss=78.4341, valid_loss=108.0714\n",
      "epoch= 36, train_loss=78.4333, valid_loss=108.0557\n",
      "epoch= 37, train_loss=78.4327, valid_loss=108.0430\n",
      "epoch= 38, train_loss=78.4323, valid_loss=108.0328\n",
      "epoch= 39, train_loss=78.4321, valid_loss=108.0247\n",
      "epoch= 40, train_loss=78.4320, valid_loss=108.0182\n",
      "epoch= 41, train_loss=78.4319, valid_loss=108.0132\n",
      "epoch= 42, train_loss=78.4320, valid_loss=108.0092\n",
      "epoch= 43, train_loss=78.4321, valid_loss=108.0062\n",
      "epoch= 44, train_loss=78.4324, valid_loss=108.0039\n",
      "epoch= 45, train_loss=78.4327, valid_loss=108.0023\n",
      "epoch= 46, train_loss=78.4330, valid_loss=108.0011\n",
      "epoch= 47, train_loss=78.4334, valid_loss=108.0003\n",
      "epoch= 48, train_loss=78.4338, valid_loss=107.9998\n",
      "epoch= 49, train_loss=78.4342, valid_loss=107.9996\n",
      "epoch= 50, train_loss=78.4347, valid_loss=107.9997\n",
      "epoch= 51, train_loss=78.4352, valid_loss=107.9999\n",
      "epoch= 52, train_loss=78.4358, valid_loss=108.0003\n",
      "epoch= 53, train_loss=78.4363, valid_loss=108.0008\n",
      "epoch= 54, train_loss=78.4369, valid_loss=108.0014\n",
      "epoch= 55, train_loss=78.4374, valid_loss=108.0020\n",
      "epoch= 56, train_loss=78.4380, valid_loss=108.0027\n",
      "epoch= 57, train_loss=78.4386, valid_loss=108.0035\n",
      "epoch= 58, train_loss=78.4391, valid_loss=108.0042\n",
      "epoch= 59, train_loss=78.4397, valid_loss=108.0051\n",
      "epoch= 60, train_loss=78.4403, valid_loss=108.0059\n",
      "epoch= 61, train_loss=78.4409, valid_loss=108.0067\n",
      "epoch= 62, train_loss=78.4415, valid_loss=108.0075\n",
      "epoch= 63, train_loss=78.4420, valid_loss=108.0084\n",
      "epoch= 64, train_loss=78.4426, valid_loss=108.0092\n",
      "epoch= 65, train_loss=78.4432, valid_loss=108.0100\n",
      "epoch= 66, train_loss=78.4437, valid_loss=108.0108\n",
      "epoch= 67, train_loss=78.4443, valid_loss=108.0116\n",
      "epoch= 68, train_loss=78.4448, valid_loss=108.0124\n",
      "epoch= 69, train_loss=78.4453, valid_loss=108.0132\n",
      "epoch= 70, train_loss=78.4459, valid_loss=108.0140\n",
      "epoch= 71, train_loss=78.4464, valid_loss=108.0147\n",
      "epoch= 72, train_loss=78.4469, valid_loss=108.0155\n",
      "epoch= 73, train_loss=78.4474, valid_loss=108.0162\n",
      "epoch= 74, train_loss=78.4479, valid_loss=108.0169\n",
      "epoch= 75, train_loss=78.4483, valid_loss=108.0176\n",
      "epoch= 76, train_loss=78.4488, valid_loss=108.0183\n",
      "epoch= 77, train_loss=78.4492, valid_loss=108.0190\n",
      "epoch= 78, train_loss=78.4497, valid_loss=108.0196\n",
      "epoch= 79, train_loss=78.4501, valid_loss=108.0202\n",
      "epoch= 80, train_loss=78.4505, valid_loss=108.0209\n",
      "epoch= 81, train_loss=78.4510, valid_loss=108.0215\n",
      "epoch= 82, train_loss=78.4514, valid_loss=108.0220\n",
      "epoch= 83, train_loss=78.4518, valid_loss=108.0226\n",
      "epoch= 84, train_loss=78.4521, valid_loss=108.0231\n",
      "epoch= 85, train_loss=78.4525, valid_loss=108.0237\n",
      "epoch= 86, train_loss=78.4529, valid_loss=108.0242\n",
      "epoch= 87, train_loss=78.4532, valid_loss=108.0247\n",
      "epoch= 88, train_loss=78.4536, valid_loss=108.0253\n",
      "epoch= 89, train_loss=78.4539, valid_loss=108.0258\n",
      "epoch= 90, train_loss=78.4543, valid_loss=108.0262\n",
      "epoch= 91, train_loss=78.4546, valid_loss=108.0267\n",
      "epoch= 92, train_loss=78.4549, valid_loss=108.0272\n",
      "epoch= 93, train_loss=78.4552, valid_loss=108.0276\n",
      "epoch= 94, train_loss=78.4555, valid_loss=108.0280\n",
      "epoch= 95, train_loss=78.4558, valid_loss=108.0285\n",
      "epoch= 96, train_loss=78.4561, valid_loss=108.0288\n",
      "epoch= 97, train_loss=78.4563, valid_loss=108.0292\n",
      "epoch= 98, train_loss=78.4566, valid_loss=108.0296\n",
      "epoch= 99, train_loss=78.4569, valid_loss=108.0300\n",
      "epoch=100, train_loss=78.4571, valid_loss=108.0304\n"
     ]
    }
   ],
   "source": [
    "# loss保存\n",
    "loss_list_train = []\n",
    "loss_list_valid = []\n",
    "total_step = int(train_num/batch_size)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    for step in range(total_step):\n",
    "        xs = x_train[step*batch_size:(step+1)*batch_size, :]\n",
    "        ys = y_train[step*batch_size:(step+1)*batch_size]\n",
    "        \n",
    "        grads = grad(xs, ys, W, B)    # 计算梯度\n",
    "        optimizer.apply_gradients(zip(grads, [W, B]))  # 调整（下降)\n",
    "    loss_train = loss(x_train, y_train, W, B).numpy()\n",
    "    loss_valid = loss(x_valid, y_valid, W, B).numpy()\n",
    "    loss_list_train.append(loss_train)\n",
    "    loss_list_valid.append(loss_valid)\n",
    "    print(\"epoch={:3d}, train_loss={:.4f}, valid_loss={:.4f}\".format(epoch+1, loss_train, loss_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20bdf588fd0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 损失变化\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(loss_list_train, 'blue', label=\"Train Loss\")\n",
    "plt.plot(loss_list_valid, 'red', label=\"Valid Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(82.5847, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(loss(x_test, y_test, W, B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House id 2 Actual value 19.4 Predicted value 20.913229\n"
     ]
    }
   ],
   "source": [
    "test_house_id = np.random.randint(0, test_num)\n",
    "y = y_test[test_house_id]\n",
    "y_pred = model(x_test, W, B)[test_house_id]\n",
    "y_predit = tf.reshape(y_pred, ()).numpy()\n",
    "print(\"House id\", test_house_id, \"Actual value\", y, \"Predicted value\", y_predit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
